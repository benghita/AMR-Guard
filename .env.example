# Med-I-C — Environment Configuration Template
# Copy this file to .env and fill in the values
# cp .env.example .env

# ── General ───────────────────────────────────────────────────────────────────
MEDIC_ENV=local                    # local | kaggle | production
MEDIC_DEFAULT_BACKEND=local        # local | vertex
MEDIC_USE_VERTEX=false
MEDIC_QUANTIZATION=4bit            # none | 4bit

# ── Local HuggingFace Models ──────────────────────────────────────────────────
# Accept model licences at huggingface.co before use.
# Swap 4B/2B substitutes for the full models on machines with ≥ 24 GB VRAM.

# Agent 1, 2, 4 — MedGemma 4B IT
# Licence: https://huggingface.co/google/medgemma-4b-it
MEDIC_LOCAL_MEDGEMMA_4B_MODEL=google/medgemma-4b-it

# Agent 3 — MedGemma 27B Text IT  (full model needs ~14 GB VRAM in 4-bit)
# Licence: https://huggingface.co/google/medgemma-27b-text-it
# Demo substitute: google/medgemma-4b-it
MEDIC_LOCAL_MEDGEMMA_27B_MODEL=google/medgemma-4b-it

# Agent 4 safety — TxGemma 9B  (full model needs ~5 GB VRAM in 4-bit)
# Licence: https://huggingface.co/google/txgemma-9b-predict
# Demo substitute: google/txgemma-2b-predict
MEDIC_LOCAL_TXGEMMA_9B_MODEL=google/txgemma-2b-predict
MEDIC_LOCAL_TXGEMMA_2B_MODEL=google/txgemma-2b-predict

# ── RAG Embedding ─────────────────────────────────────────────────────────────
MEDIC_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ── Data Paths ────────────────────────────────────────────────────────────────
MEDIC_DATA_DIR=data
MEDIC_CHROMA_DB_DIR=data/chroma_db
