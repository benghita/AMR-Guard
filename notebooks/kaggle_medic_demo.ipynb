{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med-I-C: AMR-Guard - Infection Lifecycle Orchestrator\n",
    "\n",
    "## MedGemma Impact Challenge Submission\n",
    "\n",
    "This notebook demonstrates the **Med-I-C** multi-agent system for antimicrobial stewardship:\n",
    "\n",
    "**4-Agent Architecture:**\n",
    "1. **Intake Historian** - Parse patient data, calculate CrCl, identify risk factors\n",
    "2. **Vision Specialist** - Extract structured data from lab reports (any language)\n",
    "3. **Trend Analyst** - Detect MIC creep and resistance velocity\n",
    "4. **Clinical Pharmacologist** - Final Rx recommendations with safety checks\n",
    "\n",
    "**Two Pathways:**\n",
    "- **Stage 1 (Empirical)**: Agent 1 → Agent 4 (before lab results)\n",
    "- **Stage 2 (Targeted)**: Agent 1 → Agent 2 → Agent 3 → Agent 4 (with lab results)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install dependencies\n",
    "!pip install -q langgraph>=0.0.15 langchain>=0.3.0 langchain-text-splitters\n",
    "!pip install -q chromadb>=0.4.0 sentence-transformers\n",
    "!pip install -q transformers>=4.50.0 torch accelerate bitsandbytes\n",
    "!pip install -q pydantic>=2.0 python-dotenv openpyxl requests pypdf pandas\n",
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Literal\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('MedIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hugging Face Authentication\n",
    "\n",
    "MedGemma and TxGemma require accepting the license on Hugging Face.\n",
    "\n",
    "1. Go to https://huggingface.co/google/medgemma-4b-it and accept the license\n",
    "2. Go to https://huggingface.co/google/txgemma-2b-predict and accept the license\n",
    "3. Add your HF token to Kaggle Secrets as `HF_TOKEN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Try to get token from Kaggle secrets\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "    print(\"Using HF token from Kaggle secrets\")\n",
    "except:\n",
    "    # Fallback: set your token here for local testing\n",
    "    HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")\n",
    "    if HF_TOKEN:\n",
    "        print(\"Using HF token from environment\")\n",
    "    else:\n",
    "        print(\"WARNING: No HF token found. You may need to authenticate manually.\")\n",
    "\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Configuration & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    \"medgemma_4b\": {\n",
    "        \"model_id\": \"google/medgemma-4b-it\",\n",
    "        \"description\": \"MedGemma 4B Instruction-Tuned - Primary model for all agents\",\n",
    "        \"use_4bit\": True,  # Use 4-bit quantization for memory efficiency\n",
    "    },\n",
    "    \"medgemma_27b\": {\n",
    "        \"model_id\": \"google/medgemma-27b-text-it\",\n",
    "        \"description\": \"MedGemma 27B Text IT - For complex trend analysis (requires high VRAM)\",\n",
    "        \"use_4bit\": True,\n",
    "    },\n",
    "    \"txgemma_9b\": {\n",
    "        \"model_id\": \"google/txgemma-9b-predict\",\n",
    "        \"description\": \"TxGemma 9B - Drug safety validation\",\n",
    "        \"use_4bit\": True,\n",
    "    },\n",
    "    \"txgemma_2b\": {\n",
    "        \"model_id\": \"google/txgemma-2b-predict\",\n",
    "        \"description\": \"TxGemma 2B - Lightweight safety checker fallback\",\n",
    "        \"use_4bit\": False,  # Small enough to run without quantization\n",
    "    },\n",
    "}\n",
    "\n",
    "# Display model info\n",
    "print(\"Available Models:\")\n",
    "for name, config in MODEL_CONFIG.items():\n",
    "    print(f\"  - {name}: {config['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Cache for loaded models\n",
    "_model_cache = {}\n",
    "_tokenizer_cache = {}\n",
    "\n",
    "def load_model(model_name: str = \"medgemma_4b\", force_reload: bool = False):\n",
    "    \"\"\"\n",
    "    Load a model from Hugging Face with optional 4-bit quantization.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Key from MODEL_CONFIG\n",
    "        force_reload: Force reload even if cached\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (model, tokenizer)\n",
    "    \"\"\"\n",
    "    global _model_cache, _tokenizer_cache\n",
    "    \n",
    "    if not force_reload and model_name in _model_cache:\n",
    "        print(f\"Using cached {model_name}\")\n",
    "        return _model_cache[model_name], _tokenizer_cache[model_name]\n",
    "    \n",
    "    config = MODEL_CONFIG.get(model_name)\n",
    "    if not config:\n",
    "        raise ValueError(f\"Unknown model: {model_name}. Available: {list(MODEL_CONFIG.keys())}\")\n",
    "    \n",
    "    model_id = config[\"model_id\"]\n",
    "    use_4bit = config.get(\"use_4bit\", True)\n",
    "    \n",
    "    print(f\"Loading {model_name} ({model_id})...\")\n",
    "    \n",
    "    # Configure quantization\n",
    "    load_kwargs = {\n",
    "        \"device_map\": \"auto\",\n",
    "        \"trust_remote_code\": True,\n",
    "    }\n",
    "    \n",
    "    if use_4bit and torch.cuda.is_available():\n",
    "        print(\"  Using 4-bit quantization...\")\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "        load_kwargs[\"quantization_config\"] = bnb_config\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, **load_kwargs)\n",
    "    model.eval()\n",
    "    \n",
    "    # Cache\n",
    "    _model_cache[model_name] = model\n",
    "    _tokenizer_cache[model_name] = tokenizer\n",
    "    \n",
    "    print(f\"  Loaded successfully!\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(\n",
    "    prompt: str,\n",
    "    model_name: str = \"medgemma_4b\",\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.2,\n",
    "    do_sample: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Run inference on a loaded model.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input prompt\n",
    "        model_name: Which model to use\n",
    "        max_new_tokens: Maximum tokens to generate\n",
    "        temperature: Sampling temperature\n",
    "        do_sample: Whether to use sampling\n",
    "    \n",
    "    Returns:\n",
    "        Generated text (completion only, not including prompt)\n",
    "    \"\"\"\n",
    "    model, tokenizer = load_model(model_name)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature if do_sample else None,\n",
    "            do_sample=do_sample,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # Decode only the generated part\n",
    "    generated_ids = outputs[0, inputs[\"input_ids\"].shape[1]:]\n",
    "    response = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Primary Model (MedGemma 4B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the primary model\n",
    "print(\"Loading MedGemma 4B IT (primary model for all agents)...\")\n",
    "model, tokenizer = load_model(\"medgemma_4b\")\n",
    "\n",
    "# Quick test\n",
    "test_response = run_inference(\n",
    "    \"What is ESBL? Answer in one sentence.\",\n",
    "    model_name=\"medgemma_4b\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "print(f\"\\nTest response: {test_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatinine Clearance Calculator (Cockcroft-Gault equation)\n",
    "\n",
    "def calculate_crcl(\n",
    "    age_years: float,\n",
    "    weight_kg: float,\n",
    "    serum_creatinine_mg_dl: float,\n",
    "    sex: Literal[\"male\", \"female\"],\n",
    "    height_cm: Optional[float] = None,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate Creatinine Clearance using the Cockcroft-Gault equation.\n",
    "    \n",
    "    Formula: CrCl = [(140 - age) x weight x (0.85 if female)] / (72 x SCr)\n",
    "    \"\"\"\n",
    "    if serum_creatinine_mg_dl <= 0:\n",
    "        raise ValueError(\"Serum creatinine must be positive\")\n",
    "    \n",
    "    crcl = ((140 - age_years) * weight_kg) / (72 * serum_creatinine_mg_dl)\n",
    "    \n",
    "    if sex == \"female\":\n",
    "        crcl *= 0.85\n",
    "    \n",
    "    return round(crcl, 1)\n",
    "\n",
    "\n",
    "def get_renal_dose_category(crcl: float) -> str:\n",
    "    \"\"\"Categorize renal function for dosing.\"\"\"\n",
    "    if crcl >= 90:\n",
    "        return \"normal\"\n",
    "    elif crcl >= 60:\n",
    "        return \"mild_impairment\"\n",
    "    elif crcl >= 30:\n",
    "        return \"moderate_impairment\"\n",
    "    elif crcl >= 15:\n",
    "        return \"severe_impairment\"\n",
    "    else:\n",
    "        return \"esrd\"\n",
    "\n",
    "\n",
    "# Test CrCl calculation\n",
    "test_crcl = calculate_crcl(age_years=65, weight_kg=70, serum_creatinine_mg_dl=1.2, sex=\"male\")\n",
    "print(f\"Test CrCl: {test_crcl} mL/min ({get_renal_dose_category(test_crcl)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def safe_json_parse(text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Safely parse JSON from agent output, handling markdown code blocks.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Try direct parse\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    # Try extracting from markdown code blocks\n",
    "    patterns = [\n",
    "        r\"```json\\s*\\n?(.*?)\\n?```\",\n",
    "        r\"```\\s*\\n?(.*?)\\n?```\",\n",
    "        r\"\\{[\\s\\S]*\\}\",\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                json_str = match.group(1) if match.lastindex else match.group(0)\n",
    "                return json.loads(json_str)\n",
    "            except (json.JSONDecodeError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agent Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Intake Historian\n",
    "INTAKE_HISTORIAN_SYSTEM = \"\"\"You are an expert clinical intake specialist. Your role is to:\n",
    "\n",
    "1. Parse and structure patient demographics and clinical history\n",
    "2. Calculate Creatinine Clearance (CrCl) using the Cockcroft-Gault equation when data is available\n",
    "3. Identify key risk factors for antimicrobial-resistant infections\n",
    "4. Determine the appropriate treatment stage (empirical vs targeted)\n",
    "\n",
    "RISK FACTORS TO IDENTIFY:\n",
    "- Prior MRSA or MDR infection history\n",
    "- Recent antibiotic use (within 90 days)\n",
    "- Healthcare-associated vs community-acquired infection\n",
    "- Immunocompromised status\n",
    "- Recent hospitalization or ICU stay\n",
    "- Presence of medical devices (catheters, lines)\n",
    "- Renal or hepatic impairment\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Provide a structured JSON response with the following fields:\n",
    "{\n",
    "    \"patient_summary\": \"Brief clinical summary\",\n",
    "    \"creatinine_clearance_ml_min\": <number or null>,\n",
    "    \"renal_dose_adjustment_needed\": <boolean>,\n",
    "    \"identified_risk_factors\": [\"list\", \"of\", \"factors\"],\n",
    "    \"suspected_pathogens\": [\"list\", \"of\", \"likely\", \"organisms\"],\n",
    "    \"infection_severity\": \"mild|moderate|severe|critical\",\n",
    "    \"recommended_stage\": \"empirical|targeted\",\n",
    "    \"notes\": \"Any additional clinical observations\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "INTAKE_HISTORIAN_PROMPT = \"\"\"Analyze the following patient information and provide a structured clinical assessment.\n",
    "\n",
    "PATIENT DATA:\n",
    "{patient_data}\n",
    "\n",
    "CURRENT MEDICATIONS:\n",
    "{medications}\n",
    "\n",
    "KNOWN ALLERGIES:\n",
    "{allergies}\n",
    "\n",
    "CLINICAL CONTEXT:\n",
    "- Suspected infection site: {infection_site}\n",
    "- Suspected source: {suspected_source}\n",
    "\n",
    "Provide your structured assessment following the system instructions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Vision Specialist\n",
    "VISION_SPECIALIST_SYSTEM = \"\"\"You are an expert medical laboratory data extraction specialist. Your role is to:\n",
    "\n",
    "1. Extract structured data from laboratory reports (culture & sensitivity, antibiograms)\n",
    "2. Handle reports in ANY language - always output in English\n",
    "3. Identify pathogens, antibiotics tested, MIC values, and S/I/R interpretations\n",
    "4. Flag any critical or unusual findings\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Provide a structured JSON response:\n",
    "{\n",
    "    \"specimen_type\": \"blood|urine|wound|respiratory|other\",\n",
    "    \"collection_date\": \"YYYY-MM-DD or null\",\n",
    "    \"identified_organisms\": [\n",
    "        {\n",
    "            \"organism_name\": \"Standardized English name\",\n",
    "            \"colony_count\": \"if available\",\n",
    "            \"significance\": \"pathogen|colonizer|contaminant\"\n",
    "        }\n",
    "    ],\n",
    "    \"susceptibility_results\": [\n",
    "        {\n",
    "            \"organism\": \"Organism name\",\n",
    "            \"antibiotic\": \"Standardized antibiotic name\",\n",
    "            \"mic_value\": <number or null>,\n",
    "            \"mic_unit\": \"mg/L\",\n",
    "            \"interpretation\": \"S|I|R\"\n",
    "        }\n",
    "    ],\n",
    "    \"critical_findings\": [\"List of urgent findings\"],\n",
    "    \"extraction_confidence\": 0.0-1.0\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "VISION_SPECIALIST_PROMPT = \"\"\"Extract structured laboratory data from the following report.\n",
    "\n",
    "REPORT CONTENT:\n",
    "{report_content}\n",
    "\n",
    "Extract all pathogen identifications, susceptibility results, and MIC values.\n",
    "Always standardize to English medical terminology.\n",
    "Flag any critical findings that require urgent attention.\n",
    "\n",
    "Provide your structured extraction following the system instructions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Trend Analyst\n",
    "TREND_ANALYST_SYSTEM = \"\"\"You are an expert antimicrobial resistance trend analyst. Your role is to:\n",
    "\n",
    "1. Analyze MIC trends over time to detect \"MIC Creep\"\n",
    "2. Calculate resistance velocity and predict treatment failure risk\n",
    "3. Compare current MICs against EUCAST/CLSI breakpoints\n",
    "4. Identify emerging resistance patterns\n",
    "\n",
    "RISK STRATIFICATION:\n",
    "- LOW: Stable MIC, well below breakpoint (>4x margin)\n",
    "- MODERATE: Rising trend but still 2-4x below breakpoint\n",
    "- HIGH: Approaching breakpoint (<2x margin) or rapid increase\n",
    "- CRITICAL: At or above breakpoint, or >4-fold increase over baseline\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "{\n",
    "    \"organism\": \"Pathogen name\",\n",
    "    \"antibiotic\": \"Antibiotic name\",\n",
    "    \"baseline_mic\": <number>,\n",
    "    \"current_mic\": <number>,\n",
    "    \"fold_change\": <number>,\n",
    "    \"trend\": \"stable|increasing|decreasing\",\n",
    "    \"breakpoint_susceptible\": <number>,\n",
    "    \"margin_to_breakpoint\": <number>,\n",
    "    \"risk_level\": \"LOW|MODERATE|HIGH|CRITICAL\",\n",
    "    \"recommendation\": \"Continue current therapy|Consider alternatives|Urgent switch needed\",\n",
    "    \"rationale\": \"Detailed explanation\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "TREND_ANALYST_PROMPT = \"\"\"Analyze the MIC trend data and assess resistance risk.\n",
    "\n",
    "ORGANISM: {organism}\n",
    "ANTIBIOTIC: {antibiotic}\n",
    "\n",
    "HISTORICAL MIC DATA:\n",
    "{mic_history}\n",
    "\n",
    "EUCAST BREAKPOINT (S <=): {breakpoint} mg/L\n",
    "\n",
    "Analyze the trend, calculate risk level, and provide recommendations.\n",
    "Follow the system instructions for output format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 4: Clinical Pharmacologist\n",
    "CLINICAL_PHARMACOLOGIST_SYSTEM = \"\"\"You are an expert clinical pharmacologist specializing in infectious diseases and antimicrobial stewardship. Your role is to:\n",
    "\n",
    "1. Synthesize all available clinical data into a final antibiotic recommendation\n",
    "2. Apply WHO AWaRe classification principles (ACCESS -> WATCH -> RESERVE)\n",
    "3. Perform comprehensive drug safety checks\n",
    "4. Adjust dosing for renal function\n",
    "\n",
    "PRESCRIBING PRINCIPLES:\n",
    "1. Start narrow, escalate only when justified\n",
    "2. De-escalate when culture results allow\n",
    "3. Prefer ACCESS category antibiotics when appropriate\n",
    "4. Consider pharmacokinetic/pharmacodynamic (PK/PD) optimization\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "{\n",
    "    \"primary_recommendation\": {\n",
    "        \"antibiotic\": \"Drug name\",\n",
    "        \"dose\": \"Amount and unit\",\n",
    "        \"route\": \"IV|PO|IM\",\n",
    "        \"frequency\": \"Dosing interval\",\n",
    "        \"duration\": \"Treatment duration\",\n",
    "        \"aware_category\": \"ACCESS|WATCH|RESERVE\"\n",
    "    },\n",
    "    \"alternative_recommendation\": {\n",
    "        \"antibiotic\": \"Alternative drug\",\n",
    "        \"indication\": \"When to use alternative\"\n",
    "    },\n",
    "    \"dose_adjustments\": {\n",
    "        \"renal\": \"Adjustment details or None needed\"\n",
    "    },\n",
    "    \"safety_alerts\": [\n",
    "        {\n",
    "            \"level\": \"INFO|WARNING|CRITICAL\",\n",
    "            \"message\": \"Alert message\"\n",
    "        }\n",
    "    ],\n",
    "    \"monitoring_parameters\": [\"Labs/vitals to monitor\"],\n",
    "    \"rationale\": \"Clinical reasoning\",\n",
    "    \"guideline_references\": [\"Supporting guidelines\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "CLINICAL_PHARMACOLOGIST_PROMPT = \"\"\"Synthesize all clinical data and provide a final antibiotic recommendation.\n",
    "\n",
    "PATIENT SUMMARY:\n",
    "{intake_summary}\n",
    "\n",
    "LAB RESULTS:\n",
    "{lab_results}\n",
    "\n",
    "MIC TREND ANALYSIS:\n",
    "{trend_analysis}\n",
    "\n",
    "PATIENT PARAMETERS:\n",
    "- Age: {age} years\n",
    "- Weight: {weight} kg\n",
    "- CrCl: {crcl} mL/min\n",
    "- Allergies: {allergies}\n",
    "- Current medications: {current_medications}\n",
    "\n",
    "INFECTION CONTEXT:\n",
    "- Site: {infection_site}\n",
    "- Severity: {severity}\n",
    "\n",
    "Provide your final recommendation following the system instructions.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State type definition\n",
    "from typing import TypedDict, NotRequired\n",
    "\n",
    "class InfectionState(TypedDict, total=False):\n",
    "    \"\"\"Global state for the Med-I-C pipeline.\"\"\"\n",
    "    # Patient data\n",
    "    patient_id: Optional[str]\n",
    "    age_years: Optional[float]\n",
    "    sex: Optional[Literal[\"male\", \"female\"]]\n",
    "    weight_kg: Optional[float]\n",
    "    height_cm: Optional[float]\n",
    "    \n",
    "    # Clinical context\n",
    "    suspected_source: Optional[str]\n",
    "    comorbidities: List[str]\n",
    "    medications: List[str]\n",
    "    allergies: List[str]\n",
    "    infection_site: Optional[str]\n",
    "    \n",
    "    # Renal function\n",
    "    serum_creatinine_mg_dl: Optional[float]\n",
    "    creatinine_clearance_ml_min: Optional[float]\n",
    "    \n",
    "    # Lab data\n",
    "    labs_raw_text: Optional[str]\n",
    "    mic_data: List[Dict[str, Any]]\n",
    "    \n",
    "    # Stage routing\n",
    "    stage: Literal[\"empirical\", \"targeted\"]\n",
    "    route_to_vision: bool\n",
    "    route_to_trend_analyst: bool\n",
    "    \n",
    "    # Agent outputs\n",
    "    intake_notes: Optional[str]\n",
    "    vision_notes: Optional[str]\n",
    "    trend_notes: Optional[str]\n",
    "    pharmacology_notes: Optional[str]\n",
    "    recommendation: Optional[Dict[str, Any]]\n",
    "    \n",
    "    # Safety\n",
    "    safety_warnings: List[str]\n",
    "    errors: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_intake_historian(state: InfectionState) -> InfectionState:\n",
    "    \"\"\"\n",
    "    Agent 1: Parse patient data, calculate CrCl, identify risk factors.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGENT 1: INTAKE HISTORIAN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calculate CrCl if we have required data\n",
    "    crcl = None\n",
    "    if all([state.get(\"age_years\"), state.get(\"weight_kg\"), \n",
    "            state.get(\"serum_creatinine_mg_dl\"), state.get(\"sex\")]):\n",
    "        crcl = calculate_crcl(\n",
    "            age_years=state[\"age_years\"],\n",
    "            weight_kg=state[\"weight_kg\"],\n",
    "            serum_creatinine_mg_dl=state[\"serum_creatinine_mg_dl\"],\n",
    "            sex=state[\"sex\"],\n",
    "        )\n",
    "        state[\"creatinine_clearance_ml_min\"] = crcl\n",
    "        print(f\"Calculated CrCl: {crcl} mL/min ({get_renal_dose_category(crcl)})\")\n",
    "    \n",
    "    # Build patient data string\n",
    "    patient_data = f\"\"\"\n",
    "Age: {state.get('age_years', 'Unknown')} years\n",
    "Sex: {state.get('sex', 'Unknown')}\n",
    "Weight: {state.get('weight_kg', 'Unknown')} kg\n",
    "Serum Creatinine: {state.get('serum_creatinine_mg_dl', 'Unknown')} mg/dL\n",
    "CrCl: {crcl or 'Not calculated'} mL/min\n",
    "Comorbidities: {', '.join(state.get('comorbidities', [])) or 'None reported'}\n",
    "\"\"\"\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = f\"{INTAKE_HISTORIAN_SYSTEM}\\n\\n{INTAKE_HISTORIAN_PROMPT.format(\n",
    "        patient_data=patient_data,\n",
    "        medications=', '.join(state.get('medications', [])) or 'None reported',\n",
    "        allergies=', '.join(state.get('allergies', [])) or 'No known allergies',\n",
    "        infection_site=state.get('infection_site', 'Unknown'),\n",
    "        suspected_source=state.get('suspected_source', 'Unknown'),\n",
    "    )}\"\"\"\n",
    "    \n",
    "    # Run inference\n",
    "    print(\"Running MedGemma inference...\")\n",
    "    response = run_inference(prompt, model_name=\"medgemma_4b\", max_new_tokens=1024)\n",
    "    \n",
    "    # Parse response\n",
    "    parsed = safe_json_parse(response)\n",
    "    if parsed:\n",
    "        state[\"intake_notes\"] = json.dumps(parsed, indent=2)\n",
    "        state[\"stage\"] = parsed.get(\"recommended_stage\", \"empirical\")\n",
    "        print(f\"\\nIntake Assessment:\")\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "    else:\n",
    "        state[\"intake_notes\"] = response\n",
    "        state[\"stage\"] = \"empirical\"\n",
    "        print(f\"\\nRaw response: {response[:500]}...\")\n",
    "    \n",
    "    # Determine routing\n",
    "    state[\"route_to_vision\"] = bool(state.get(\"labs_raw_text\"))\n",
    "    print(f\"\\nStage: {state['stage']}\")\n",
    "    print(f\"Route to Vision Specialist: {state['route_to_vision']}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vision_specialist(state: InfectionState) -> InfectionState:\n",
    "    \"\"\"\n",
    "    Agent 2: Extract structured data from lab reports.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGENT 2: VISION SPECIALIST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    labs_raw = state.get(\"labs_raw_text\", \"\")\n",
    "    if not labs_raw:\n",
    "        print(\"No lab data to process, skipping.\")\n",
    "        state[\"vision_notes\"] = \"No lab data provided\"\n",
    "        state[\"route_to_trend_analyst\"] = False\n",
    "        return state\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt = f\"{VISION_SPECIALIST_SYSTEM}\\n\\n{VISION_SPECIALIST_PROMPT.format(\n",
    "        report_content=labs_raw,\n",
    "    )}\"\n",
    "    \n",
    "    # Run inference\n",
    "    print(\"Running MedGemma inference on lab report...\")\n",
    "    response = run_inference(prompt, model_name=\"medgemma_4b\", max_new_tokens=2048)\n",
    "    \n",
    "    # Parse response\n",
    "    parsed = safe_json_parse(response)\n",
    "    if parsed:\n",
    "        state[\"vision_notes\"] = json.dumps(parsed, indent=2)\n",
    "        \n",
    "        # Extract MIC data\n",
    "        susceptibility = parsed.get(\"susceptibility_results\", [])\n",
    "        state[\"mic_data\"] = susceptibility\n",
    "        state[\"route_to_trend_analyst\"] = len(susceptibility) > 0\n",
    "        \n",
    "        print(f\"\\nExtracted Lab Data:\")\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "        \n",
    "        # Check for critical findings\n",
    "        critical = parsed.get(\"critical_findings\", [])\n",
    "        if critical:\n",
    "            print(f\"\\n⚠️ CRITICAL FINDINGS: {critical}\")\n",
    "            state.setdefault(\"safety_warnings\", []).extend(critical)\n",
    "    else:\n",
    "        state[\"vision_notes\"] = response\n",
    "        state[\"route_to_trend_analyst\"] = False\n",
    "        print(f\"\\nRaw response: {response[:500]}...\")\n",
    "    \n",
    "    print(f\"\\nMIC data points: {len(state.get('mic_data', []))}\")\n",
    "    print(f\"Route to Trend Analyst: {state.get('route_to_trend_analyst', False)}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trend_analyst(state: InfectionState) -> InfectionState:\n",
    "    \"\"\"\n",
    "    Agent 3: Analyze MIC trends and detect resistance velocity.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGENT 3: TREND ANALYST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    mic_data = state.get(\"mic_data\", [])\n",
    "    if not mic_data:\n",
    "        print(\"No MIC data to analyze, skipping.\")\n",
    "        state[\"trend_notes\"] = \"No MIC data available\"\n",
    "        return state\n",
    "    \n",
    "    trend_results = []\n",
    "    \n",
    "    for mic in mic_data:\n",
    "        organism = mic.get(\"organism\", \"Unknown\")\n",
    "        antibiotic = mic.get(\"antibiotic\", \"Unknown\")\n",
    "        mic_value = mic.get(\"mic_value\")\n",
    "        \n",
    "        if mic_value is None:\n",
    "            continue\n",
    "        \n",
    "        # For demo, create synthetic history showing increasing trend\n",
    "        mic_history = json.dumps([\n",
    "            {\"date\": \"2024-01-01\", \"mic_value\": float(mic_value) / 2},\n",
    "            {\"date\": \"2024-06-01\", \"mic_value\": float(mic_value) / 1.5},\n",
    "            {\"date\": \"2025-01-01\", \"mic_value\": float(mic_value)},\n",
    "        ], indent=2)\n",
    "        \n",
    "        # Use standard EUCAST breakpoint (simplified)\n",
    "        breakpoint = 2.0  # Default S <= 2 mg/L\n",
    "        \n",
    "        prompt = f\"{TREND_ANALYST_SYSTEM}\\n\\n{TREND_ANALYST_PROMPT.format(\n",
    "            organism=organism,\n",
    "            antibiotic=antibiotic,\n",
    "            mic_history=mic_history,\n",
    "            breakpoint=breakpoint,\n",
    "        )}\"\n",
    "        \n",
    "        print(f\"\\nAnalyzing: {organism} / {antibiotic}...\")\n",
    "        response = run_inference(prompt, model_name=\"medgemma_4b\", max_new_tokens=1024)\n",
    "        \n",
    "        parsed = safe_json_parse(response)\n",
    "        if parsed:\n",
    "            trend_results.append(parsed)\n",
    "            risk_level = parsed.get(\"risk_level\", \"UNKNOWN\")\n",
    "            print(f\"  Risk Level: {risk_level}\")\n",
    "            \n",
    "            if risk_level in [\"HIGH\", \"CRITICAL\"]:\n",
    "                warning = f\"MIC trend alert for {organism}/{antibiotic}: {parsed.get('recommendation', 'Review needed')}\"\n",
    "                state.setdefault(\"safety_warnings\", []).append(warning)\n",
    "        else:\n",
    "            trend_results.append({\"organism\": organism, \"antibiotic\": antibiotic, \"raw\": response[:200]})\n",
    "    \n",
    "    state[\"trend_notes\"] = json.dumps(trend_results, indent=2)\n",
    "    print(f\"\\nTrend Analysis Complete:\")\n",
    "    print(json.dumps(trend_results, indent=2))\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clinical_pharmacologist(state: InfectionState) -> InfectionState:\n",
    "    \"\"\"\n",
    "    Agent 4: Generate final antibiotic recommendation with safety checks.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGENT 4: CLINICAL PHARMACOLOGIST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Gather previous agent outputs\n",
    "    intake_summary = state.get(\"intake_notes\", \"No intake data\")\n",
    "    lab_results = state.get(\"vision_notes\", \"No lab data\")\n",
    "    trend_analysis = state.get(\"trend_notes\", \"No trend data\")\n",
    "    \n",
    "    prompt = f\"{CLINICAL_PHARMACOLOGIST_SYSTEM}\\n\\n{CLINICAL_PHARMACOLOGIST_PROMPT.format(\n",
    "        intake_summary=intake_summary,\n",
    "        lab_results=lab_results,\n",
    "        trend_analysis=trend_analysis,\n",
    "        age=state.get('age_years', 'Unknown'),\n",
    "        weight=state.get('weight_kg', 'Unknown'),\n",
    "        crcl=state.get('creatinine_clearance_ml_min', 'Unknown'),\n",
    "        allergies=', '.join(state.get('allergies', [])) or 'No known allergies',\n",
    "        current_medications=', '.join(state.get('medications', [])) or 'None',\n",
    "        infection_site=state.get('infection_site', 'Unknown'),\n",
    "        severity='moderate',\n",
    "    )}\"\n",
    "    \n",
    "    print(\"Running MedGemma inference for final recommendation...\")\n",
    "    response = run_inference(prompt, model_name=\"medgemma_4b\", max_new_tokens=2048)\n",
    "    \n",
    "    parsed = safe_json_parse(response)\n",
    "    if parsed:\n",
    "        state[\"pharmacology_notes\"] = json.dumps(parsed, indent=2)\n",
    "        \n",
    "        # Build recommendation\n",
    "        primary = parsed.get(\"primary_recommendation\", {})\n",
    "        recommendation = {\n",
    "            \"primary_antibiotic\": primary.get(\"antibiotic\"),\n",
    "            \"dose\": primary.get(\"dose\"),\n",
    "            \"route\": primary.get(\"route\"),\n",
    "            \"frequency\": primary.get(\"frequency\"),\n",
    "            \"duration\": primary.get(\"duration\"),\n",
    "            \"rationale\": parsed.get(\"rationale\"),\n",
    "            \"references\": parsed.get(\"guideline_references\", []),\n",
    "            \"safety_alerts\": [a.get(\"message\") for a in parsed.get(\"safety_alerts\", [])],\n",
    "        }\n",
    "        \n",
    "        alt = parsed.get(\"alternative_recommendation\", {})\n",
    "        if alt.get(\"antibiotic\"):\n",
    "            recommendation[\"backup_antibiotic\"] = alt.get(\"antibiotic\")\n",
    "        \n",
    "        state[\"recommendation\"] = recommendation\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"FINAL RECOMMENDATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(json.dumps(recommendation, indent=2))\n",
    "        \n",
    "        # Add safety alerts\n",
    "        for alert in parsed.get(\"safety_alerts\", []):\n",
    "            if alert.get(\"level\") in [\"WARNING\", \"CRITICAL\"]:\n",
    "                state.setdefault(\"safety_warnings\", []).append(alert.get(\"message\"))\n",
    "    else:\n",
    "        state[\"pharmacology_notes\"] = response\n",
    "        state[\"recommendation\"] = {\"rationale\": response}\n",
    "        print(f\"\\nRaw response: {response[:500]}...\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pipeline Orchestration with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def build_infection_graph():\n",
    "    \"\"\"\n",
    "    Build the LangGraph StateGraph for the infection lifecycle workflow.\n",
    "    \n",
    "    Stage 1 (Empirical): Intake Historian -> Clinical Pharmacologist\n",
    "    Stage 2 (Targeted): Intake Historian -> Vision Specialist -> Trend Analyst -> Clinical Pharmacologist\n",
    "    \"\"\"\n",
    "    graph = StateGraph(InfectionState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph.add_node(\"intake_historian\", run_intake_historian)\n",
    "    graph.add_node(\"vision_specialist\", run_vision_specialist)\n",
    "    graph.add_node(\"trend_analyst\", run_trend_analyst)\n",
    "    graph.add_node(\"clinical_pharmacologist\", run_clinical_pharmacologist)\n",
    "    \n",
    "    # Set entry point\n",
    "    graph.set_entry_point(\"intake_historian\")\n",
    "    \n",
    "    # Conditional routing after intake\n",
    "    def route_after_intake(state: InfectionState):\n",
    "        if state.get(\"stage\") == \"targeted\" and state.get(\"route_to_vision\"):\n",
    "            return \"vision_specialist\"\n",
    "        return \"clinical_pharmacologist\"\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"intake_historian\",\n",
    "        route_after_intake,\n",
    "        {\n",
    "            \"vision_specialist\": \"vision_specialist\",\n",
    "            \"clinical_pharmacologist\": \"clinical_pharmacologist\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Conditional routing after vision\n",
    "    def route_after_vision(state: InfectionState):\n",
    "        if state.get(\"route_to_trend_analyst\"):\n",
    "            return \"trend_analyst\"\n",
    "        return \"clinical_pharmacologist\"\n",
    "    \n",
    "    graph.add_conditional_edges(\n",
    "        \"vision_specialist\",\n",
    "        route_after_vision,\n",
    "        {\n",
    "            \"trend_analyst\": \"trend_analyst\",\n",
    "            \"clinical_pharmacologist\": \"clinical_pharmacologist\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Edges to final node\n",
    "    graph.add_edge(\"trend_analyst\", \"clinical_pharmacologist\")\n",
    "    graph.add_edge(\"clinical_pharmacologist\", END)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "def run_pipeline(patient_data: dict, labs_raw_text: Optional[str] = None) -> InfectionState:\n",
    "    \"\"\"\n",
    "    Run the full infection lifecycle pipeline.\n",
    "    \n",
    "    Args:\n",
    "        patient_data: Patient information dict\n",
    "        labs_raw_text: Optional lab report text (triggers Stage 2)\n",
    "    \n",
    "    Returns:\n",
    "        Final InfectionState with recommendation\n",
    "    \"\"\"\n",
    "    # Build initial state\n",
    "    initial_state: InfectionState = {\n",
    "        \"age_years\": patient_data.get(\"age_years\"),\n",
    "        \"weight_kg\": patient_data.get(\"weight_kg\"),\n",
    "        \"height_cm\": patient_data.get(\"height_cm\"),\n",
    "        \"sex\": patient_data.get(\"sex\"),\n",
    "        \"serum_creatinine_mg_dl\": patient_data.get(\"serum_creatinine_mg_dl\"),\n",
    "        \"medications\": patient_data.get(\"medications\", []),\n",
    "        \"allergies\": patient_data.get(\"allergies\", []),\n",
    "        \"comorbidities\": patient_data.get(\"comorbidities\", []),\n",
    "        \"infection_site\": patient_data.get(\"infection_site\"),\n",
    "        \"suspected_source\": patient_data.get(\"suspected_source\"),\n",
    "        \"safety_warnings\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "    \n",
    "    # Add lab data if provided\n",
    "    if labs_raw_text:\n",
    "        initial_state[\"labs_raw_text\"] = labs_raw_text\n",
    "        initial_state[\"stage\"] = \"targeted\"\n",
    "    else:\n",
    "        initial_state[\"stage\"] = \"empirical\"\n",
    "    \n",
    "    # Build and run graph\n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(f\"# STARTING MED-I-C PIPELINE (Stage: {initial_state['stage'].upper()})\")\n",
    "    print(\"#\"*70)\n",
    "    \n",
    "    graph = build_infection_graph()\n",
    "    compiled = graph.compile()\n",
    "    final_state = compiled.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    print(\"# PIPELINE COMPLETE\")\n",
    "    print(\"#\"*70)\n",
    "    \n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 1: Stage 1 (Empirical) - Community UTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: Stage 1 Empirical - Community UTI\n",
    "patient_data_uti = {\n",
    "    \"age_years\": 65,\n",
    "    \"weight_kg\": 70,\n",
    "    \"height_cm\": 170,\n",
    "    \"sex\": \"male\",\n",
    "    \"serum_creatinine_mg_dl\": 1.2,\n",
    "    \"medications\": [\"metformin\", \"lisinopril\", \"aspirin\"],\n",
    "    \"allergies\": [\"penicillin\"],\n",
    "    \"comorbidities\": [\"diabetes\", \"hypertension\"],\n",
    "    \"infection_site\": \"urinary\",\n",
    "    \"suspected_source\": \"community-acquired UTI\",\n",
    "}\n",
    "\n",
    "result_uti = run_pipeline(patient_data_uti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST CASE 1: COMMUNITY UTI (EMPIRICAL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nCrCl: {result_uti.get('creatinine_clearance_ml_min')} mL/min\")\n",
    "print(f\"Stage: {result_uti.get('stage')}\")\n",
    "\n",
    "rec = result_uti.get('recommendation', {})\n",
    "if rec:\n",
    "    print(f\"\\nRecommendation:\")\n",
    "    print(f\"  Drug: {rec.get('primary_antibiotic')}\")\n",
    "    print(f\"  Dose: {rec.get('dose')}\")\n",
    "    print(f\"  Route: {rec.get('route')}\")\n",
    "    print(f\"  Frequency: {rec.get('frequency')}\")\n",
    "    print(f\"  Duration: {rec.get('duration')}\")\n",
    "    print(f\"  Rationale: {rec.get('rationale')}\")\n",
    "\n",
    "warnings = result_uti.get('safety_warnings', [])\n",
    "if warnings:\n",
    "    print(f\"\\nSafety Warnings:\")\n",
    "    for w in warnings:\n",
    "        print(f\"  ⚠️ {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 2: Stage 2 (Targeted) - With Lab Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Stage 2 Targeted - UTI with Lab Results\n",
    "patient_data_targeted = {\n",
    "    \"age_years\": 72,\n",
    "    \"weight_kg\": 65,\n",
    "    \"height_cm\": 165,\n",
    "    \"sex\": \"female\",\n",
    "    \"serum_creatinine_mg_dl\": 1.5,\n",
    "    \"medications\": [\"warfarin\", \"amlodipine\"],\n",
    "    \"allergies\": [],\n",
    "    \"comorbidities\": [\"atrial fibrillation\", \"hypertension\", \"CKD stage 3\"],\n",
    "    \"infection_site\": \"urinary\",\n",
    "    \"suspected_source\": \"complicated UTI with pyelonephritis\",\n",
    "}\n",
    "\n",
    "lab_report = \"\"\"\n",
    "URINE CULTURE REPORT\n",
    "Patient ID: 12345\n",
    "Collection Date: 2025-02-15\n",
    "\n",
    "Specimen: Midstream urine\n",
    "Colony Count: >100,000 CFU/mL\n",
    "\n",
    "ORGANISM ISOLATED:\n",
    "Escherichia coli\n",
    "\n",
    "ANTIMICROBIAL SUSCEPTIBILITY:\n",
    "-----------------------------------\n",
    "Antibiotic          MIC (mg/L)   Interpretation\n",
    "-----------------------------------\n",
    "Ampicillin          >32          R\n",
    "Amoxicillin-Clav    16           I\n",
    "Ceftriaxone         0.25         S\n",
    "Cefepime            0.5          S\n",
    "Ciprofloxacin       0.5          S\n",
    "Levofloxacin        1            S\n",
    "Nitrofurantoin      32           S\n",
    "TMP-SMX             >4           R\n",
    "Gentamicin          2            S\n",
    "Meropenem           0.06         S\n",
    "\n",
    "NOTES:\n",
    "- ESBL screening negative\n",
    "- No carbapenemase detected\n",
    "\"\"\"\n",
    "\n",
    "result_targeted = run_pipeline(patient_data_targeted, labs_raw_text=lab_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST CASE 2: COMPLICATED UTI WITH LAB RESULTS (TARGETED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nCrCl: {result_targeted.get('creatinine_clearance_ml_min')} mL/min\")\n",
    "print(f\"Stage: {result_targeted.get('stage')}\")\n",
    "\n",
    "print(f\"\\nExtracted MIC Data:\")\n",
    "for mic in result_targeted.get('mic_data', []):\n",
    "    print(f\"  - {mic.get('organism')} / {mic.get('antibiotic')}: MIC {mic.get('mic_value')} ({mic.get('interpretation')})\")\n",
    "\n",
    "rec = result_targeted.get('recommendation', {})\n",
    "if rec:\n",
    "    print(f\"\\nFinal Recommendation:\")\n",
    "    print(f\"  Primary: {rec.get('primary_antibiotic')}\")\n",
    "    print(f\"  Dose: {rec.get('dose')}\")\n",
    "    print(f\"  Route: {rec.get('route')}\")\n",
    "    print(f\"  Frequency: {rec.get('frequency')}\")\n",
    "    print(f\"  Duration: {rec.get('duration')}\")\n",
    "    if rec.get('backup_antibiotic'):\n",
    "        print(f\"  Alternative: {rec.get('backup_antibiotic')}\")\n",
    "    print(f\"  Rationale: {rec.get('rationale')}\")\n",
    "\n",
    "warnings = result_targeted.get('safety_warnings', [])\n",
    "if warnings:\n",
    "    print(f\"\\n⚠️ Safety Warnings:\")\n",
    "    for w in warnings:\n",
    "        print(f\"  - {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 3: ESBL-producing Organism (High-Risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 3: ESBL E. coli\n",
    "patient_esbl = {\n",
    "    \"age_years\": 58,\n",
    "    \"weight_kg\": 85,\n",
    "    \"height_cm\": 175,\n",
    "    \"sex\": \"male\",\n",
    "    \"serum_creatinine_mg_dl\": 1.0,\n",
    "    \"medications\": [\"metformin\", \"atorvastatin\"],\n",
    "    \"allergies\": [],\n",
    "    \"comorbidities\": [\"diabetes\", \"recent hospitalization\"],\n",
    "    \"infection_site\": \"bloodstream\",\n",
    "    \"suspected_source\": \"healthcare-associated bacteremia\",\n",
    "}\n",
    "\n",
    "lab_esbl = \"\"\"\n",
    "BLOOD CULTURE REPORT\n",
    "Collection Date: 2025-02-18\n",
    "\n",
    "POSITIVE: Gram-negative bacilli\n",
    "\n",
    "FINAL IDENTIFICATION:\n",
    "Escherichia coli (ESBL-producing)\n",
    "\n",
    "ANTIMICROBIAL SUSCEPTIBILITY:\n",
    "-----------------------------------\n",
    "Antibiotic          MIC (mg/L)   Interpretation\n",
    "-----------------------------------\n",
    "Ampicillin          >32          R\n",
    "Ampicillin-Sulbact  >32          R\n",
    "Ceftriaxone         >32          R\n",
    "Cefepime            >32          R\n",
    "Ceftazidime         >32          R\n",
    "Ciprofloxacin       >4           R\n",
    "Levofloxacin        >8           R\n",
    "TMP-SMX             >4           R\n",
    "Gentamicin          8            I\n",
    "Amikacin            4            S\n",
    "Ertapenem           0.25         S\n",
    "Meropenem           0.06         S\n",
    "Imipenem            0.5          S\n",
    "Tigecycline         0.5          S\n",
    "\n",
    "ESBL CONFIRMATION: POSITIVE\n",
    "Carbapenemase: NOT DETECTED\n",
    "\n",
    "CRITICAL ALERT: ESBL-producing organism in bloodstream\n",
    "\"\"\"\n",
    "\n",
    "result_esbl = run_pipeline(patient_esbl, labs_raw_text=lab_esbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ESBL results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST CASE 3: ESBL E. coli BACTEREMIA (HIGH-RISK)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rec = result_esbl.get('recommendation', {})\n",
    "if rec:\n",
    "    print(f\"\\nRecommendation:\")\n",
    "    print(f\"  Primary: {rec.get('primary_antibiotic')}\")\n",
    "    print(f\"  Dose: {rec.get('dose')}\")\n",
    "    print(f\"  Route: {rec.get('route')}\")\n",
    "    print(f\"  Rationale: {rec.get('rationale')}\")\n",
    "\n",
    "warnings = result_esbl.get('safety_warnings', [])\n",
    "if warnings:\n",
    "    print(f\"\\n🚨 SAFETY ALERTS:\")\n",
    "    for w in warnings:\n",
    "        print(f\"  - {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Streamlit App (Optional - for local testing)\n",
    "\n",
    "Note: Streamlit doesn't run directly in Kaggle notebooks. To test the Streamlit app:\n",
    "1. Download this notebook and the source files\n",
    "2. Run locally with `streamlit run app.py`\n",
    "\n",
    "Alternatively, you can use `ngrok` or `localtunnel` to expose the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install and run Streamlit with localtunnel\n",
    "# Uncomment to use\n",
    "\n",
    "# !pip install -q streamlit localtunnel\n",
    "\n",
    "# # Write the app file\n",
    "# app_code = '''\n",
    "# import streamlit as st\n",
    "# import json\n",
    "\n",
    "# st.set_page_config(page_title=\"Med-I-C: AMR-Guard\", page_icon=\"🦠\", layout=\"wide\")\n",
    "\n",
    "# st.title(\"🦠 Med-I-C: AMR-Guard\")\n",
    "# st.subheader(\"Infection Lifecycle Orchestrator - Multi-Agent System\")\n",
    "\n",
    "# st.markdown(\"\"\"\n",
    "# This demo showcases the Med-I-C multi-agent system powered by MedGemma.\n",
    "\n",
    "# **Note:** Running in demo mode. For full functionality, deploy with GPU support.\n",
    "# \"\"\")\n",
    "\n",
    "# # Patient form\n",
    "# with st.form(\"patient_form\"):\n",
    "#     col1, col2 = st.columns(2)\n",
    "#     with col1:\n",
    "#         age = st.number_input(\"Age\", 0, 120, 65)\n",
    "#         weight = st.number_input(\"Weight (kg)\", 1.0, 300.0, 70.0)\n",
    "#         sex = st.selectbox(\"Sex\", [\"male\", \"female\"])\n",
    "#     with col2:\n",
    "#         creatinine = st.number_input(\"Creatinine (mg/dL)\", 0.1, 20.0, 1.2)\n",
    "#         infection_site = st.selectbox(\"Infection Site\", [\"urinary\", \"respiratory\", \"bloodstream\"])\n",
    "#     \n",
    "#     submitted = st.form_submit_button(\"Get Recommendation\")\n",
    "\n",
    "# if submitted:\n",
    "#     st.success(\"Demo mode: Showing simulated recommendation\")\n",
    "#     st.json({\n",
    "#         \"primary_antibiotic\": \"Ciprofloxacin\",\n",
    "#         \"dose\": \"500mg\",\n",
    "#         \"route\": \"PO\",\n",
    "#         \"frequency\": \"Every 12 hours\",\n",
    "#         \"duration\": \"7 days\"\n",
    "#     })\n",
    "# '''\n",
    "\n",
    "# with open('streamlit_app.py', 'w') as f:\n",
    "#     f.write(app_code)\n",
    "\n",
    "# # Run with localtunnel\n",
    "# !streamlit run streamlit_app.py &>/dev/null &\n",
    "# !npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary & Conclusions\n",
    "\n",
    "This notebook demonstrates the **Med-I-C** multi-agent system for antimicrobial stewardship:\n",
    "\n",
    "### Key Features:\n",
    "1. **4 Specialized Agents** powered by MedGemma 4B IT\n",
    "2. **Conditional Routing** via LangGraph for Stage 1 (Empirical) vs Stage 2 (Targeted)\n",
    "3. **CrCl Calculation** using Cockcroft-Gault equation\n",
    "4. **MIC Trend Analysis** for resistance detection\n",
    "5. **Safety Checks** including drug interactions and allergy alerts\n",
    "\n",
    "### Models Used:\n",
    "- **MedGemma 4B IT** - Primary model for all agents (4-bit quantized)\n",
    "- **TxGemma 2B** - Optional safety validation (not demonstrated in this notebook)\n",
    "\n",
    "### Future Enhancements:\n",
    "- Integration with RAG (ChromaDB) for guideline retrieval\n",
    "- MedGemma 27B for complex trend analysis\n",
    "- Vision capabilities for image-based lab report extraction\n",
    "- Regional resistance pattern analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Competition:** MedGemma Impact Challenge  \n",
    "**Category:** Agentic Workflow  \n",
    "**Deadline:** February 24, 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final memory cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU Memory after cleanup: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
